{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647f46ed-c149-4abc-b148-af8c0808c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb66805-c964-4415-af7f-b4b9f408f909",
   "metadata": {},
   "source": [
    "# Generate Synthetic Attribute Data with different settings\n",
    "Always generate 10 datasets with the same settings.\n",
    "\n",
    "Out of the 10 change points, the first 5 are always explainable with attributes 1, 2, 3, 4 and 5. The last 5 are not explainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc675551-b730-4da3-aa24-80f61db08636",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log_size = 10000\n",
    "relevant_attributes = 5\n",
    "irrelevant_attributes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9774dbd-a0dd-46b4-a4f2-acb61b5f51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 random event logs from the maardji et al 2013 dataset that are of the desired size\n",
    "suitable_dataset= helper.get_datasets_by_criteria(size=event_log_size, \n",
    "                                             has_generated_attributes=False, \n",
    "                                             dataset='maardji et al 2013')\n",
    "datasets = np.random.choice(list(suitable_event_logs.keys()), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c04c89-9965-4049-8579-1cf35295c55c",
   "metadata": {},
   "source": [
    "## Scenario 1: New material, new vendor...\n",
    "\n",
    "Data is categorical. One new category is added which is sampled at 10%. All other categories are sampled at random distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c5beb-3311-41f0-ab9f-d837e87b4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'data/synthetic/generated/new_attribute_values/'\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_info = helper.get_data_information(dataset)\n",
    "    opyenxes_log = helper.opyenxes_read_xes(dataset_info['file_path'])\n",
    "    ag = generate_attributes.AttributeGenerator(opyenxes_log, dataset_info['change_points'])\n",
    "    \n",
    "    attribute_1_base_line_distribution = [0.6, 0.4, 0]\n",
    "    attribute_1_changed_distribution = [0.5, 0.3, 0.2]\n",
    "    \n",
    "    for attribute_index in range(relevant_attribute_count):\n",
    "        attribute_name = f'relevant_attribute_{attribute_index + 1}'\n",
    "        # changepoint to explain\n",
    "        explain_changepoint = dataset_info['change_points'][attribute_index]\n",
    "        ag.generate_categorical_attribute(attribute_name, \n",
    "                                          change_location_standard_deviation=0, \n",
    "                                          explain_change_points=[dataset_info['change_points'][attribute_index]],\n",
    "                                          noise_level=0,\n",
    "                                          count_attribute_values=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
