{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change_points(series, threshold, min_observations_below, min_distance_change_streaks):\n",
    "    \"\"\"Gets a list of changepoints from a series of observations based on a threshold. \n",
    "    \n",
    "    A change point is registered if the series values are below the threshold for the duration of 'min_observations_below'. \n",
    "    Change points will only be flagged if there is at least a distance of 'min_distance_change_streaks' between streaks of observations below the change point.\n",
    "    \n",
    "    Args:\n",
    "        series: Pandas series with observations.\n",
    "        \n",
    "    Returns:\n",
    "        List of change points.\n",
    "    \"\"\"\n",
    "    # for each row, get whether its value is of threshold or lower\n",
    "    series_below_threshold = series <= threshold\n",
    "\n",
    "    # do an accumulative count of how many values below the threshold have been observed\n",
    "    # restarts at 0 as soon as one value > threshold is observed\n",
    "    below_threshold_counts = series_below_threshold * (series_below_threshold.groupby((series_below_threshold != series_below_threshold.shift()).cumsum()).cumcount() + 1)\n",
    "    \n",
    "    # reset the index of below_threshold_counts to 0...n instead of trace counts\n",
    "    true_indices_series = below_threshold_counts.index\n",
    "    below_threshold_counts = below_threshold_counts.reset_index(drop=True)\n",
    "\n",
    "    # store change points as indices\n",
    "    change_points = []\n",
    "    \n",
    "    # ix when the last streak ended\n",
    "    last_change_streak_ended = None\n",
    "\n",
    "    for index, streak_count in below_threshold_counts.iteritems():\n",
    "        if streak_count < min_observations_below:\n",
    "            continue\n",
    "        \n",
    "        # check if the streak is exactly the minimum number of observations\n",
    "        if streak_count == min_observations_below:\n",
    "            \n",
    "            integer_index_candidate = index - min_observations_below + 1\n",
    "            change_point_candidate = true_indices_series[integer_index_candidate]\n",
    "            \n",
    "            # definitely enter the change point if this is the first streak that was seen\n",
    "            if last_change_streak_ended is None:\n",
    "                change_points.append(change_point_candidate)\n",
    "            else:\n",
    "                # get distance to last streak end\n",
    "                distance_to_last_streak = integer_index_candidate - last_change_streak_ended - 1\n",
    "\n",
    "                if distance_to_last_streak >= min_distance_change_streaks:\n",
    "                    change_points.append(change_point_candidate)\n",
    "\n",
    "        # update the end of the last change streak, if the current streak count exceeds the min observations below threshold\n",
    "        if streak_count >= min_observations_below:\n",
    "            last_change_streak_ended = index\n",
    "    \n",
    "    return change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_1</th>\n",
       "      <th>pop_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radio</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comp</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TV</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Comp</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Comp</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Radio</td>\n",
       "      <td>Radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TV</td>\n",
       "      <td>Radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TV</td>\n",
       "      <td>Radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Radio</td>\n",
       "      <td>Radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Comp</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Comp</td>\n",
       "      <td>Comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TV</td>\n",
       "      <td>Radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pop_1  pop_2\n",
       "0      TV     TV\n",
       "1   Radio     TV\n",
       "2    Comp   Comp\n",
       "3      TV     TV\n",
       "4      TV     TV\n",
       "5      TV   Comp\n",
       "6    Comp   Comp\n",
       "7    Comp   Comp\n",
       "8      TV     TV\n",
       "9   Radio  Radio\n",
       "10     TV     TV\n",
       "11     TV  Radio\n",
       "12     TV  Radio\n",
       "13  Radio  Radio\n",
       "14   Comp   Comp\n",
       "15   Comp   Comp\n",
       "16     TV     TV\n",
       "17     TV     TV\n",
       "18     TV  Radio\n",
       "19     TV     TV"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = ['asdf'] * 0 + ['akdsjfiev'] * 2001 + ['adfviie'] * 3000 + ['lkadkf'] * 4000\n",
    "array_2 = ['asdf'] * 3999 + ['akdsjfiev'] * 3001 + ['adfviie'] * 2000 + ['lkadkf'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency_table_pandas(array_1, array_2):\n",
    "    df = pd.DataFrame().from_dict({'pop_1': array_1,\n",
    "                   'pop_2': array_2})\n",
    "    value_counts_df = df.apply(pd.value_counts)\n",
    "    value_counts_df = value_counts_df.transpose()\n",
    "    return value_counts_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processdrift.framework import pop_comparison\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3000, 2001,  999, 4000],\n",
       "       [2000, 3001, 3999, 1000]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_comparison.get_contingency_table(array_1, array_2)\n",
    "get_contingency_table_pandas(array_1, array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.539812999999981"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_implementation = timeit.Timer(lambda: pop_comparison.get_contingency_table(array_1, array_2)).timeit(number=1000)\n",
    "current_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3947099000000094"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_implementation = timeit.Timer(lambda: get_contingency_table_pandas(array_1, array_2)).timeit(number=1000)\n",
    "new_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2001., 3000., 4000.,   nan],\n",
       "       [3001., 2000., 1000., 3999.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def using_counter(array_1, array_2):\n",
    "    pop_1_counter = Counter(array_1)\n",
    "    pop_2_counter = Counter(array_2)\n",
    "    df = pd.DataFrame().from_dict({'pop_1': pop_1_counter, 'pop_2': pop_2_counter}, orient='index')\n",
    "    return df.to_numpy()\n",
    "using_counter(array_1, array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None, 4000, 2001, 3000],\n",
       "       [3999, 1000, 3001, 2000]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "pop_1_counter = Counter(array_1)\n",
    "pop_2_counter = Counter(array_2)\n",
    "result_array = []\n",
    "\n",
    "keys = list(pop_1_counter.keys() | pop_2_counter.keys())\n",
    "result_array = []\n",
    "\n",
    "for dict in [pop_1_counter, pop_2_counter]:\n",
    "    result_array.append([dict.get(key) for key in keys])\n",
    "\n",
    "np.array(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 4000, 2001, 3000]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pop_1_counter.get(key) for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2001, 3000, 4000],\n",
       "       [3999, 3001, 2000]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def no_pandas(array_1, array_2):\n",
    "    pop_1_counter = Counter(array_1)\n",
    "    pop_2_counter = Counter(array_2)\n",
    "\n",
    "    result_array = []\n",
    "\n",
    "    for (k,v), (k2,v2) in zip(pop_1_counter.items(), pop_2_counter.items()):\n",
    "            result_array.append([v, v2])\n",
    "\n",
    "    result = np.array(result_array).transpose()\n",
    "    return result\n",
    "no_pandas(array_1, array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None, 4000, 2001, 3000],\n",
       "       [3999, 1000, 3001, 2000]], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_pandas2(array_1, array_2):\n",
    "    pop_1_counter = Counter(array_1)\n",
    "    pop_2_counter = Counter(array_2)\n",
    "    result_array = []\n",
    "\n",
    "    keys = list(pop_1_counter.keys() | pop_2_counter.keys())\n",
    "    result_array = []\n",
    "\n",
    "    for dict in [pop_1_counter, pop_2_counter]:\n",
    "        result_array.append([dict.get(key) for key in keys])\n",
    "\n",
    "    return np.array(result_array)\n",
    "no_pandas2(array_1, array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748181299999942"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_implementation = timeit.Timer(lambda: no_pandas2(array_1, array_2)).timeit(number=1000)\n",
    "counter_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>pop_1</th>\n",
       "      <th>Comp</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Radio</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_2</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Radio</th>\n",
       "      <th>TV</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Radio</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Comp</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radio</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pop_1 Comp Radio      TV         \n",
       "pop_2 Comp Radio TV Comp Radio TV\n",
       "pop_1                            \n",
       "Comp     5     0  0    0     0  0\n",
       "Radio    0     2  1    0     0  0\n",
       "TV       0     0  0    1     3  8"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['pop_1']).count()\n",
    "\n",
    "pd.crosstab(index=df['pop_1'], columns=[df['pop_1'],df['pop_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000      0\n",
       "33.333333     0\n",
       "66.666667     1\n",
       "100.000000    0\n",
       "133.333333    0\n",
       "166.666667    1\n",
       "200.000000    1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 100.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_list = [0, 0, 1, 0, 0, 1, 1] # 1 cp at index 60 (=iloc 3)\n",
    "\n",
    "series = pd.Series(series_list, index=np.linspace(0, 200, len(series_list)))\n",
    "display(series)\n",
    "\n",
    "get_change_points(series, threshold=0.05, min_observations_below=1, min_distance_change_streaks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _get_distribution(attribute_value_count):\n",
    "    \"\"\"Get a single distribution for a given number of values.\n",
    "    \n",
    "    Args:\n",
    "        number_values: How many different values the distribution should have.\n",
    "    \n",
    "    Returns:\n",
    "        A probability distribution.\n",
    "    \"\"\"\n",
    "    distribution = np.random.dirichlet(np.ones(attribute_value_count)).tolist()\n",
    "    return distribution\n",
    "\n",
    "def _get_distribution_new(attribute_value_count, min_probability=0.1):\n",
    "    \"\"\"Get a single distribution for a given number of values.\n",
    "    \n",
    "    Args:\n",
    "        number_values: How many different values the distribution should have.\n",
    "        min_probability: Minimum probability per attribute value.\n",
    "    \n",
    "    Returns:\n",
    "        A probability distribution.\n",
    "    \"\"\"\n",
    "    # generate a random number per attribute_value_count\n",
    "    # each attribute probability should be at least min_percent -> return an error if this cannot be satisfied\n",
    "    if attribute_value_count * min_probability > 1:\n",
    "        raise Exception(\"'min_probability' too high for the number of attribute values.\")\n",
    "\n",
    "    sampled_random_numbers = np.random.random(attribute_value_count)\n",
    "    distribution_random = sampled_random_numbers / sum(sampled_random_numbers)\n",
    "    distribution = [min_probability + (1-min_probability) * random for random in distribution_random]\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.633906699013631e-07\n",
      "0.10000300725504244\n"
     ]
    }
   ],
   "source": [
    "attribute_value_count = 3\n",
    "experiments = 100000\n",
    "dichilet_mins = [min(_get_distribution(attribute_value_count)) for _ in range(experiments)]\n",
    "own_mins = [min(_get_distribution_new(attribute_value_count)) for _ in range(experiments)]\n",
    "print(np.array(dichilet_mins).min())\n",
    "print(np.array(own_mins).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_1_array = ['asd'] * 20 + ['alsdkf'] * 15 + ['aksdf'] * 10 + ['laksdfe'] * 0\n",
    "pop_2_array = ['asd'] * 6 + ['alsdkf'] * 10 + ['aksdf'] * 15 + ['laksdfe'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency_table(pop_1_array, pop_2_array):\n",
    "    \"\"\"Get a numpy contingency table from two arrays of samples.\n",
    "    \n",
    "    Args:\n",
    "        pd_series_1: First sample array.\n",
    "        pd_series_2: Second sample array.\n",
    "    \"\"\"\n",
    "    # get pandas series for both arrays of observations so that we can calculate the value counts next\n",
    "    pop_1 = pd.Series(pop_1_array)\n",
    "    pop_2 = pd.Series(pop_2_array)\n",
    "\n",
    "    # get the observation frequencies\n",
    "    pop_1_frequencies = pop_1.value_counts()\n",
    "    pop_2_frequencies = pop_2.value_counts()\n",
    "\n",
    "    # create the contingency table, fill in NaN with 0\n",
    "    contingency_table_df = pd.DataFrame([pop_1_frequencies, pop_2_frequencies])\n",
    "    contingency_table_df = contingency_table_df.fillna(0)\n",
    "\n",
    "    # convert to numpy array\n",
    "    contingency_table = contingency_table_df.to_numpy()\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20., 15., 10.,  0.],\n",
       "       [ 6., 10., 15.,  1.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table = get_contingency_table(pop_1_array, pop_2_array)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if one value is NaN or < 5, return\n",
    "(contingency_table < 5).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0352937477047853"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if one value is NaN or < 5, return\n",
    "(contingency_table < 5).any()\n",
    "\n",
    "# calculate the chi-squared p-value\n",
    "stat, p, dof, expected = scipy.stats.chi2_contingency(contingency_table)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027392347410116178"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the G-test p-value\n",
    "stat, p, dof, expected = scipy.stats.chi2_contingency(contingency_table, lambda_=\"log-likelihood\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.19480519, 14.61038961, 14.61038961,  0.58441558],\n",
       "       [10.80519481, 10.38961039, 10.38961039,  0.41558442]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def process(i):\n",
    "    return i * i\n",
    "    \n",
    "results = Parallel(n_jobs=2)(delayed(process)(i) for i in range(10))\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locale import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def preprocess_get_contingency_table(pop_1_array, pop_2_array):\n",
    "    \"\"\"Get a numpy contingency table from two arrays of samples.\n",
    "    \n",
    "    Args:\n",
    "        pd_series_1: First sample array.\n",
    "        pd_series_2: Second sample array.\n",
    "\n",
    "    Returns:\n",
    "        numpy contingency table\n",
    "    \"\"\"\n",
    "    pop_1_counter = Counter(pop_1_array)\n",
    "    pop_2_counter = Counter(pop_2_array)\n",
    "    result_array = []\n",
    "\n",
    "    keys = list(pop_1_counter.keys() | pop_2_counter.keys())\n",
    "    result_array = []\n",
    "\n",
    "    for dict in [pop_1_counter, pop_2_counter]:\n",
    "        result_array.append([dict.get(key, 0) for key in keys])\n",
    "\n",
    "    return np.array(result_array)\n",
    "\n",
    "def preprocess_get_distribution_table(pop_1_array, pop_2_array):\n",
    "    \"\"\"Gets a distribution table. This table is like a contingency table but normalizes the occurence frequncies.\n",
    "        \n",
    "    Args:\n",
    "        pd_series_1: First sample array.\n",
    "        pd_series_2: Second sample array.\n",
    "    \"\"\"\n",
    "    contingency_table = preprocess_get_contingency_table(pop_1_array, pop_2_array)\n",
    "    sum_of_rows = contingency_table.sum(axis=1)\n",
    "    normalized_array = contingency_table / sum_of_rows[:, np.newaxis]\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = ['a']*1 + ['b']*2\n",
    "array_2 = ['a']*4 + ['b'] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, q = preprocess_get_distribution_table(array_1, array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('upc_ir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82dedc04ea80db69e61fe0f8a5aa6ffcdec9126a8fcbb32582dc55388d809d83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
